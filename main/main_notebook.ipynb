{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc45d4e-a3b9-41a8-8365-b4908ee4f76d",
   "metadata": {},
   "source": [
    "# Project Selection\n",
    "## Topic Selection\n",
    "- **Overal idea**: Texture classification using contact microphone data from robotic hand\n",
    "- **Analysis approaches**:\n",
    "  - 1D Convolutional Neural Network (CNN) on time-series data\n",
    "  - 2D CNN on spectrogram\n",
    "  - Hidden Markov Model (HMM) on time-series\n",
    "  - HMM on spectrogram\n",
    "- **Problem statement**: Can CNNs outperform HMM models for texture classification tasks on acoustic contact-sensing data gathered from a robotic hand\n",
    "- **Relevant resources**:\n",
    "  - [AU Dataset for Visuo-Haptic Object Recognition for Robots](https://arxiv.org/pdf/2112.13761.pdf)\n",
    "  - [Publicly available datatset](https://figshare.com/articles/dataset/AU_Dataset_for_Visuo-Haptic_Object_Recognition_for_Robots/14222486)\n",
    "  - [Another publicly available dataset](https://arxiv.org/pdf/2307.00937.pdf)\n",
    "- **Precedent literature**:\n",
    "  - [Journal: identifying pill type based on acoustic data gathered via shaking motion](https://tams.informatik.uni-hamburg.de/people/jonetzko/publications/jonetzko2020multimodal.pdf)\n",
    "  - [Object classification with transmission acoustic sensing (Prof. Culbertson)](https://arxiv.org/pdf/2308.01600.pdf)\n",
    "  - [Fabric classification based on acoustic data gathered via sliding motion (dataset avilable)](https://www.frontiersin.org/articles/10.3389/fnbot.2022.808222/full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48cbf294-866b-4a84-bb01-b0381eabfdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1031, 0.4530, 0.1348],\n",
      "        [0.9834, 0.8297, 0.9469],\n",
      "        [0.7635, 0.3847, 0.8169],\n",
      "        [0.5393, 0.8654, 0.7956],\n",
      "        [0.5823, 0.3987, 0.1955]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c1821",
   "metadata": {},
   "source": [
    "### Signal Processing Steps\n",
    "- Hamming window *before* spectral analysis (from *Isolated-word speech recognition using hidden Markov models*)\n",
    "- Remove ambient spectrum (from *A soft, amorphous skin that can sense and localize textures*)\n",
    "    - How?\n",
    "- Scale data by mean and standard deviation and re-sample to account for different time-series lengths (from *Fabric Classification Using a Finger-Shaped Tactile Sensor via Robotic Sliding*)\n",
    "- Extracting features from the time-series beyond frequency bins (from: *Design of a Biomimetic Tactile Sensor for Material Classification*)\n",
    "- Spectral subtraction (from: *Evaluating Integration Strategies for Visuo-Haptic Object Recognition*)\n",
    "    - Cited paper: \n",
    "- Rebinning frequency spectrum (from: *Stane: Synthesized surfaces for tactile input*)\n",
    "\n",
    "### Classification\n",
    "- CNN + transformer (from: *An Investigation of Multi-feature Extraction and Super-resolution with Fast Microphone Arrays*)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
