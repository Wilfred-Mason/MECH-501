{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc45d4e-a3b9-41a8-8365-b4908ee4f76d",
   "metadata": {},
   "source": [
    "# Project Selection\n",
    "## Topic Selection\n",
    "- **Overal idea**: Texture classification using contact microphone data from robotic hand\n",
    "- **Analysis approaches**:\n",
    "  - 1D Convolutional Neural Network (CNN) on time-series data\n",
    "  - 2D CNN on spectrogram\n",
    "  - Hidden Markov Model (HMM) on time-series\n",
    "  - HMM on spectrogram\n",
    "- **Problem statement**: Can CNNs outperform HMM models for texture classification tasks on acoustic contact-sensing data gathered from a robotic hand\n",
    "- **Relevant resources**:\n",
    "  - [AU Dataset for Visuo-Haptic Object Recognition for Robots](/papers/AU%20Dataset%20for%20Visuo-Haptic%20Object%20Recognition%20for%20Robots.pdf)\n",
    "    - [Link to datatset](https://figshare.com/articles/dataset/AU_Dataset_for_Visuo-Haptic_Object_Recognition_for_Robots/14222486)\n",
    "  - [A Biomimetic Fingerprint for Robotic Tactile Sensing](/papers/A%20Biomimetic%20Fingerprint%20for%20Robotic%20Tactile%20Sensing.pdf)\n",
    "    - [Link to dataset](https://figshare.com/articles/dataset/Supplementary_Material_for_A_Biomimetic_Fingerprint_for_Robotic_Tactile_Sensing_/21120982)\n",
    "\n",
    "  - [Journal: identifying pill type based on acoustic data gathered via shaking motion](https://tams.informatik.uni-hamburg.de/people/jonetzko/publications/jonetzko2020multimodal.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c1821",
   "metadata": {},
   "source": [
    "### Research\n",
    "- Hamming window *before* spectral analysis (from [Isolated-word speech recognition using hidden Markov models](/papers/Isolated-word%20speech%20recognition%20using%20hidden%20Markov%20models.pdf))\n",
    "    - Also mentioned in paper is the fact that since training examples are concatenated, the probability of transitioning from the last state to the initial state is captured\n",
    "    - A modified Baum-Welch algorithm has been developed to avoid this potential issue\n",
    "- Remove ambient spectrum (from [A soft, amorphous skin that can sense and localize textures](/papers/A%20soft,%20amorphous%20skin%20that%20can%20sense%20and%20localize%20textures.pdf))\n",
    "    - Details in [An efficient algorithm to estimate the instantaneous SNR of speech signals](/papers/An%20Efficient%20Algorithm%20to%20Estimate%20the%20Instantaneous%20SNR%20of%20Speech%20Signals.pdf) (estimates noise during periods of **speech** activity)\n",
    "    - More details in [Spectral Subtraction Based on Minimum Statistics](/papers/Spectral%20Subtraction%20Based%20on%20Minimum%20Statistics%20THESIS.pdf)\n",
    "- Scale data by mean and standard deviation and re-sample to account for different time-series lengths (from [Fabric Classification Using a Finger-Shaped Tactile Sensor via Robotic Sliding](/papers/Fabric%20Classification%20Using%20a%20Finger-Shaped%20Tactile%20Sensor%20via%20Robotic%20Sliding.pdf))\n",
    "- Extracting features from the time-series beyond frequency bins (from [Design of a Biomimetic Tactile Sensor for Material Classification](/papers/Design%20of%20a%20Biomimetic%20Tactile%20Sensor%20for%20Material%20Classification.pdf))\n",
    "- Spectral subtraction (from [Evaluating Integration Strategies for Visuo-Haptic Object Recognition](/papers/Evaluating%20Integration%20Strategies%20for%20Visuo-Haptic%20Object%20Recognition.pdf))\n",
    "    - Cited paper: [Suppression of Acoustic Noise in Speech Using Spectral Subtraction](/papers/Suppression%20of%20acoustic%20noise%20in%20speech%20using%20spectral%20subtraction.pdf) (estimate noise spectrum during periods of **non-speech** activity)\n",
    "- Re-binning frequency spectrum (from [Stane: Synthesized surfaces for tactile input](/papers/Stane%20Synthesized%20surfaces%20for%20tactile%20input.pdf))\n",
    "- Spectral noise subtraction ([explanations and examples](https://abhipray.com/posts/sigproc/classic_speech_enhancement/spectral_subtraction/))\n",
    "- Classification approach: CNN + transformer (from [An Investigation of Multi-feature Extraction and Super-resolution with Fast Microphone Arrays](/papers/An%20Investigation%20of%20Multi-feature%20Extraction%20and%20Super-resolution%20with%20Fast%20Microphone%20Arrays.pdf))\n",
    "- [Multimodal Object Analysis with Auditory and Tactile Sensing using Recurrent Neural Networks](/papers/Multimodal%20Object%20Analysis%20with%20Auditory%20and%20Tactile%20Sensing%20using%20Recurrent%20Neural%20Networks.pdf)\n",
    "    - Mel Frequency Cepstral Coefficents (MFCC) used for feature extraction (MFCC parameters found using Tree-Parzen-based hyperparameter optimization)\n",
    "    - LSTM-based architecture\n",
    "    \n",
    "### Resources\n",
    "- [HMMlearn speech example (1)](https://blog.goodaudience.com/music-genre-classification-using-hidden-markov-models-4a7f14eb0fd4)\n",
    "- [HMMlearn speech example (2)](https://maharshi-yeluri.medium.com/understanding-and-implementing-speech-recognition-using-hmm-6a4e7666de1)\n",
    "- [Multi-variate 1D CNN example](https://github.com/harryjdavies/Python1D_CNNs/blob/master/CCN1D_pytorch_activity.py)\n",
    "- [CNN dimensions example](https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/)\n",
    "- [StackExchange thread about dimensions](https://stackoverflow.com/questions/67842116/how-do-i-properly-package-multi-channel-time-series-data-and-build-the-network-f)\n",
    "- [LSTM explaination](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2cb14c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0844, 0.5088, 0.1909],\n",
      "        [0.0827, 0.7211, 0.7862],\n",
      "        [0.4412, 0.8704, 0.2868],\n",
      "        [0.2071, 0.2094, 0.7199],\n",
      "        [0.9722, 0.9868, 0.3530]])\n",
      "torch.Size([3, 64, 4])\n",
      "torch.Size([3, 64, 2])\n",
      "torch.Size([3, 128])\n",
      "torch.Size([3, 100])\n",
      "torch.Size([3, 6])\n",
      "torch.Size([3, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilfr\\AppData\\Local\\Temp\\ipykernel_17244\\1857672190.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input)\n",
      "c:\\Users\\wilfr\\Documents\\Graduate Research\\MECH-501\\Assignment_2\\MECH-501\\main\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#importing PyTorch test\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "#experimenting with dimensions\n",
    "input = np.array([[[1, 2, 3, 4],[1, 2, 3, 4]],[[1, 2, 3, 4],[1, 2, 3, 4]],[[1, 2, 3, 4],[1, 2, 3, 4]]])\n",
    "input = torch.from_numpy(input).float()\n",
    "input = torch.tensor(input)\n",
    "m_1 = nn.Conv1d(2, 64, kernel_size=1)\n",
    "m_2 = nn.MaxPool1d(2)\n",
    "m_3 = nn.Flatten()\n",
    "m_4 = nn.Linear(128,100)\n",
    "m_5 =  nn.Linear(100,6)\n",
    "m_6 =  nn.Softmax()\n",
    "\n",
    "print(input.size())\n",
    "output = m_1(input)\n",
    "print(output.size())\n",
    "output = m_2(output)\n",
    "print(output.size())\n",
    "output = m_3(output)\n",
    "print(output.size())\n",
    "output = m_4(output)\n",
    "print(output.size())\n",
    "output = m_5(output)\n",
    "print(output.size())\n",
    "output = m_6(output)\n",
    "print(output.size())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
